{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1MuGp3lZIkadV6YeIi59EoKxnUwbxejwf","authorship_tag":"ABX9TyOSCxu3qkwcAS7SwQkhXH6I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mVtsQDyhc9sT"},"outputs":[],"source":["# Importing needed libraries\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","import os\n","from PIL import Image\n","\n"]},{"cell_type":"code","source":["# connecting to drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","data_path = '/content/drive/MyDrive/NTI project/garbage-dataset'\n","test_path = '/content/drive/MyDrive/NTI project/test_ds'"],"metadata":{"id":"auGHN4atfWjz","executionInfo":{"status":"ok","timestamp":1752561602558,"user_tz":-180,"elapsed":16646,"user":{"displayName":"Abram Eisa","userId":"12904919808036253141"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"14ad25d9-4c2e-4bde-fca4-14d96e61a71c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# checking the validity of data paths and the number of files in each class\n","# from genericpath import isdir\n","for classes in os.listdir(data_path):\n","  class_path = os.path.join(data_path, classes)\n","  # print(class_path)\n","  if os.path.isdir(class_path):\n","    files = os.listdir(class_path)\n","    print(f\"{classes}: {len(files)} files\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mOUUOoR1vYMT","executionInfo":{"status":"ok","timestamp":1752561637248,"user_tz":-180,"elapsed":27226,"user":{"displayName":"Abram Eisa","userId":"12904919808036253141"}},"outputId":"c0def4e5-b6e4-4769-c092-77b2a62f020e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["battery: 851 files\n","shoes: 1777 files\n","cardboard: 1635 files\n","plastic: 1784 files\n","trash: 897 files\n","glass: 2761 files\n","clothes: 5195 files\n","paper: 1518 files\n","biological: 897 files\n","metal: 920 files\n"]}]},{"cell_type":"code","source":["# checking for non-image files\n","\n","valid_extensions = ('.jpg','.png','.jepg')\n","\n","for classes in os.listdir(data_path):\n","  class_path = os.path.join(data_path, classes)\n","  if os.path.isdir(class_path):\n","    for current_file in os.listdir(class_path):\n","      if not current_file.lower().endswith(valid_extensions):\n","        print(f\"{current_file} is not an image\")\n","\n","# no non-image files detected"],"metadata":{"id":"-AWahCKRwExa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#checking for corrupted files\n","\n","from PIL import Image\n","\n","corrupted_images = []\n","\n","for classes in os.listdir(data_path):\n","  class_path = os.path.join(data_path, classes)\n","  if os.path.isdir(class_path):\n","    for corrent_file in os.listdir(class_path):\n","      file_path = os.path.join(class_path, corrent_file)\n","      try :\n","        with Image.open(file_path) as img :\n","          img.verify()  #verify if image can be oppened or not\n","      except (IOError, SyntaxError) as e:\n","        print(f\"corrupted file : {file_path}\")\n","        corrupted_images.append(file_path)\n","\n","# No corrupted files are found using PIL"],"metadata":{"id":"RDBaivNeymVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#checking for corrupted files using tensorflow\n","bad_files =[]\n","\n","for classes in os.listdir(data_path):\n","  class_path = os.path.join(data_path, classes)\n","  if os.path.isdir(class_path):\n","    for corrent_file in os.listdir(class_path):\n","      file_path = os.path.join(class_path, corrent_file)\n","      try:\n","        img_raw = tf.io.read_file(file_path)\n","        img_tensor = tf.io.decode_image(img_raw, channels=3, expand_animations=False)\n","      except Exception as e:\n","        print(f\"TensorFlow failed to load the file:{file_path}, error: {e}\")\n","        bad_files.append(file_path)\n","\n","bad_files\n","# Found two corrupted files"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TsBX6Z-Y6NxN","executionInfo":{"status":"ok","timestamp":1752533630842,"user_tz":-180,"elapsed":186784,"user":{"displayName":"Abram Eisa","userId":"12904919808036253141"}},"outputId":"c66b23d5-b0fe-408d-8360-0814d2d517f9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#checking for corrupted files using tensorflow\n","bad_files_test =[]\n","\n","for classes in os.listdir(test_path):\n","  class_path = os.path.join(test_path, classes)\n","  if os.path.isdir(class_path):\n","    for corrent_file in os.listdir(class_path):\n","      file_path = os.path.join(class_path, corrent_file)\n","      try:\n","        img_raw = tf.io.read_file(file_path)\n","        img_tensor = tf.io.decode_image(img_raw, channels=3, expand_animations=False)\n","      except Exception as e:\n","        print(f\"TensorFlow failed to load the file:{file_path}, error: {e}\")\n","        bad_files_test.append(file_path)\n","\n","bad_files_test\n","\n","#Found one corruoted files in the test data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PbMfrJ6j-MHq","executionInfo":{"status":"ok","timestamp":1752533444054,"user_tz":-180,"elapsed":141741,"user":{"displayName":"Abram Eisa","userId":"12904919808036253141"}},"outputId":"5cd48264-8607-4002-ab25-d6402ad54387"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# deleting currupted images\n","\n","for corrupted_images in bad_files:\n","  try:\n","    os.remove(corrupted_images)\n","    print(f\"{corrupted_images} is removed\")\n","  except Exception as e:\n","    print(f\"failed to remove {corrupted_images}, error: {e}\\n\")\n","\n","for corrupted_images in bad_files_test:\n","  try:\n","    os.remove(corrupted_images)\n","    print(f\"{corrupted_images} is removed\")\n","  except Exception as e:\n","    print(f\"failed to remove {corrupted_images}, error: {e}\\n\")"],"metadata":{"id":"n3X46lKNDdj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Loading clear data\n","data_dir = '/content/drive/MyDrive/NTI project/garbage-dataset'\n","test_dir = '/content/drive/MyDrive/NTI project/test_ds'\n","\n","for classes in os.listdir(data_path):\n","  class_path = os.path.join(data_path, classes)\n","  # print(class_path)\n","  if os.path.isdir(class_path):\n","    files = os.listdir(class_path)\n","    print(f\"{classes}: {len(files)} files\") # the output shows that the paper data has lost 2 images (recheck the above cell to ensure that)"],"metadata":{"id":"MsCKgkUnfux5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752561717900,"user_tz":-180,"elapsed":165,"user":{"displayName":"Abram Eisa","userId":"12904919808036253141"}},"outputId":"afadfe82-acb0-46da-dde2-0dfe8579401b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["battery: 851 files\n","shoes: 1777 files\n","cardboard: 1635 files\n","plastic: 1784 files\n","trash: 897 files\n","glass: 2761 files\n","clothes: 5195 files\n","paper: 1518 files\n","biological: 897 files\n","metal: 920 files\n"]}]},{"cell_type":"code","source":["# Splitting data\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory (\n","    data_dir,\n","    subset = 'training',\n","    batch_size = 32,\n","    image_size = (180,180),\n","    shuffle = True,\n","    seed = 123,\n","    validation_split = 0.3,\n","    interpolation='nearest',\n",")\n","\n","val_ds = tf.keras.preprocessing.image_dataset_from_directory (\n","    data_dir,\n","    subset = 'validation',\n","    batch_size = 32,\n","    image_size = (180,180),\n","    shuffle = False,\n","    seed = 123,\n","    validation_split = 0.3,\n","    interpolation='nearest'\n",")\n","\n","test_ds = tf.keras.preprocessing.image_dataset_from_directory (\n","    test_dir,\n","    batch_size = 32,\n","    image_size = (180,180),\n","    shuffle = False,\n","    seed = 123,\n","    interpolation='nearest'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KNrVucI0Z_tn","executionInfo":{"status":"ok","timestamp":1752561856384,"user_tz":-180,"elapsed":9443,"user":{"displayName":"Abram Eisa","userId":"12904919808036253141"}},"outputId":"e7226046-84d4-4140-a00a-ec1fa307f697"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 18235 files belonging to 10 classes.\n","Using 12765 files for training.\n","Found 18235 files belonging to 10 classes.\n","Using 5470 files for validation.\n","Found 1524 files belonging to 10 classes.\n"]}]},{"cell_type":"code","source":["#visualising data\n","class_names = train_ds.class_names\n","for images, labels in train_ds.take(1):\n","    plt.figure(figsize=(10, 10))\n","    for i in range(9):  # Show 9 images\n","        ax = plt.subplot(3, 3, i + 1)\n","        plt.imshow(images[i].numpy().astype(\"uint8\"))\n","        plt.title(class_names[labels[i]])\n","        plt.axis(\"off\")\n"],"metadata":{"id":"1NA-etyJgcqe","executionInfo":{"status":"error","timestamp":1752692779658,"user_tz":-180,"elapsed":183,"user":{"displayName":"Abram Eisa","userId":"12904919808036253141"}},"colab":{"base_uri":"https://localhost:8080/","height":220},"outputId":"df85659a-0dc3-4ea8-de17-08b2fd6f1583"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'train_ds' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1-3756711450.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#visualising data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Show 9 images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"]}]},{"cell_type":"code","source":["# preprocessing\n","\n","#normalization\n","normalization = tf.keras.layers.Rescaling(1.0/255)\n","\n","train_ds = train_ds.map(lambda x, y: (normalization(x),y))\n","val_ds = val_ds.map(lambda x,y:(normalization(x),y))\n","test_ds = test_ds.map(lambda x,y:(normalization(x),y))\n","\n","#augmentaion\n","\n","augmentation = tf.keras.Sequential([\n","    # layers.RandomBrightness(0.1),\n","    layers.RandomContrast(0.1),\n","    layers.RandomFlip('Horizental'),\n","    layers.RandomRotation(0.1),\n","    layers.RandomZoom(0.2)\n","])\n","\n","train_ds = train_ds.map(lambda x,y: (augmentation(x, training=True),y))\n","\n","train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n","val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n","test_ds = test_ds.prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"VtxJmQCcgyFH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model construction and training\n","\n","model = tf.keras.Sequential ([\n","    # first convlution layer\n","    layers.Conv2D(64, kernel_size=3),\n","    layers.BatchNornalization(),\n","    layers.activation('relu')\n","    layers.AveragePooling2D(pool_size=2, strides=1),\n","\n","\n","    layers.Flatten(),\n","\n","    layers.Dense(256, activation='relu'),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(10, activation='softmax'),\n","])"],"metadata":{"id":"EAHzHNa-iVsj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model compilation and training\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","model.fit(train_ds, validation_data=val_ds, epochs=5)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dbh8pvFGoLwm","outputId":"93eb5102-d631-43bf-8ec1-34f0fd0811ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]}]},{"cell_type":"code","source":["# Saving model\n","model.save('model_1_5epochs.keras')"],"metadata":{"id":"jAKaMiJjOMO1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6zWbik87OuYb"},"execution_count":null,"outputs":[]}]}